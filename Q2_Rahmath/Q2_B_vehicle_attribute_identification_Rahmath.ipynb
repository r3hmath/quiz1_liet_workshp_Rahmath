{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKHrBUjMG-Uw",
        "outputId": "f1f91609-d0e3-4d99-def8-09bece41cfde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files in dataset: ['20250901.104645.912.J001A1.SL.FR.NaN.NaN.jpg', '20250901.153410.209.J001A1.SL.FR.NaN.NaN.jpg', '20250904.072631.739.J001A1.SL.FR.NaN.NaN.jpg', '20250910.200345.132.J001A1.FL.FR.NaN.NaN.jpg', '20250915.133513.973.J001A1.FL.FR.PUTRAJAYA9558.NaN.jpg', '20250915.154453.318.J001A1.FL.RE.L2233.NaN.jpg', '20250915.164521.488.J001A1.SL.FR.MALAYSIA1834.NaN.jpg', '20250915.172302.451.J001A1.FL.RE.PATRIOT1513.NaN.jpg', '20250917.071629.915.J001A1.SL.FR.JUM5353.NaN.jpg', '20250917.071700.908.J001A1.SL.FR.WB5138N.NaN.jpg', '20250917.071924.072.J001A1.SL.RE.JXV718.NaN.jpg', '20250917.071940.201.J001A1.FL.FR.JXC2052.NaN.jpg', '20250917.072920.154.J001A1.SL.FR.JVM3445.NaN.jpg', '20250917.073006.305.J001A1.SL.FR.JTQ5254.NaN.jpg', '20250917.085912.220.J001A1.SL.RE.JJ1975.NaN.jpg', '20250917.090217.279.J001A1.FL.FR.UT4583.NaN.jpg', '20250917.090217.640.J001A1.FL.RE.JUY4583.NaN.jpg', '20250917.090445.972.J001A1.FL.FR.BPE4281.NaN.jpg', '20250917.090639.150.J001A1.SL.RE.CDD1917.NaN.jpg', '20250917.113527.935.J001A1.SL.FR.JTH9557.NaN.jpg', '20250917.113727.571.J001A1.SL.FR.WJL.NaN.jpg', '20250917.113850.167.J001A1.FL.FR.W8273T.NaN.jpg', '20250917.114059.611.J001A1.SL.FR.JUJ9760.NaN.jpg']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Path to your dataset\n",
        "dataset_path = r\"C:\\Users\\fayaf\\Downloads\\FaceRec_Rahmath\\Q2_Rahmath\\vehicle_dataset\\q2_Images\"\n",
        "\n",
        "# List files inside the folder\n",
        "print(\"Files in dataset:\", os.listdir(dataset_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNLr9nd3He6D",
        "outputId": "4b6a22e0-364c-495e-b9ae-c98e9ae3d87a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.203  Python-3.10.18 torch-2.8.0+cpu CPU (Intel Core i5-1035G1 1.00GHz)\n",
            "Setup complete  (8 CPUs, 7.8 GB RAM, 278.1/288.4 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-8x4IKSqp3j",
        "outputId": "94cec53e-4da9-49fb-c222-d7fd7cf65070"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.457473 0.376522 0.395380 0.662609\n",
            "1 0.456793 0.650435 0.201087 0.069565\n",
            "2 0.450000 0.576522 0.057065 0.064348\n"
          ]
        }
      ],
      "source": [
        "label_path = r\"C:\\Users\\fayaf\\Downloads\\FaceRec_Rahmath\\Q2_Rahmath\\vehicle_dataset\\q2_labels\"\n",
        "sample_file = os.listdir(label_path)[0]\n",
        "\n",
        "with open(os.path.join(label_path, sample_file), \"r\") as f:\n",
        "    print(f.read())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5rOptS1qriv",
        "outputId": "d649aa17-11ec-4b93-e79e-b0198e3ec10c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unmatched images: set()\n",
            "Unmatched labels: set()\n"
          ]
        }
      ],
      "source": [
        "images = [os.path.splitext(f)[0] for f in os.listdir(dataset_path)]\n",
        "labels = [os.path.splitext(f)[0] for f in os.listdir(label_path)]\n",
        "\n",
        "print(\"Unmatched images:\", set(images) - set(labels))\n",
        "print(\"Unmatched labels:\", set(labels) - set(images))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpONda4aq1qw",
        "outputId": "96198888-911d-4c2d-93b3-5079a03901ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "created!\n"
          ]
        }
      ],
      "source": [
        "yaml_content = \"\"\"\n",
        "train: /content/drive/MyDrive/vehicle_attribute_identification/vehicle_dataset/images/train\n",
        "val: /content/drive/MyDrive/vehicle_attribute_identification/vehicle_dataset/images/val\n",
        "\n",
        "nc: 14\n",
        "names: [ 'truck', 'license_plate', 'logo', 'car', 'bike', 'bus', 'nissan', 'toyota', 'isuzu', 'mitsubishi', 'proton', 'mazda', 'mercedes', 'honda' ]\n",
        "\n",
        "nc: 14\n",
        "names: [ 'truck', 'license_plate', 'logo', 'car', 'bike', 'bus', 'nissan', 'toyota', 'isuzu', 'mitsubishi', 'proton', 'mazda', 'mercedes', 'honda' ]\n",
        "\"\"\"\n",
        "\n",
        "with open(\"data.yaml\", \"w\") as f:\n",
        "    f.write(yaml_content)\n",
        "print(\"created!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKz2FWvXriAa",
        "outputId": "113acf34-0f40-4a43-a4d8-01e93a2dc51d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dataset organized into YOLO format\n"
          ]
        }
      ],
      "source": [
        "import os, shutil, random\n",
        "\n",
        "base = r\"C:\\Users\\fayaf\\Downloads\\FaceRec_Rahmath\\Q2_Rahmath\\vehicle_dataset\"\n",
        "\n",
        "# Make YOLO folders\n",
        "os.makedirs(f\"{base}/images/train\", exist_ok=True)\n",
        "os.makedirs(f\"{base}/images/val\", exist_ok=True)\n",
        "os.makedirs(f\"{base}/labels/train\", exist_ok=True)\n",
        "os.makedirs(f\"{base}/labels/val\", exist_ok=True)\n",
        "\n",
        "# Get all images\n",
        "images = [f for f in os.listdir(f\"{base}/q2_Images\") if f.endswith(('.jpg','.png','.jpeg'))]\n",
        "\n",
        "# Train/val split (80/20)\n",
        "random.shuffle(images)\n",
        "split = int(0.8 * len(images))\n",
        "train_imgs, val_imgs = images[:split], images[split:]\n",
        "\n",
        "# Move files into correct folders\n",
        "for img in train_imgs:\n",
        "    name, ext = os.path.splitext(img)\n",
        "    shutil.copy(f\"{base}/q2_Images/{img}\", f\"{base}/images/train/{img}\")\n",
        "    shutil.copy(f\"{base}/q2_labels/{name}.txt\", f\"{base}/labels/train/{name}.txt\")\n",
        "\n",
        "for img in val_imgs:\n",
        "    name, ext = os.path.splitext(img)\n",
        "    shutil.copy(f\"{base}/q2_Images/{img}\", f\"{base}/images/val/{img}\")\n",
        "    shutil.copy(f\"{base}/q2_labels/{name}.txt\", f\"{base}/labels/val/{name}.txt\")\n",
        "\n",
        "print(\"✅ Dataset organized into YOLO format\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6BxI5GkvHdt",
        "outputId": "cfff5cb1-fa70-49de-9678-d08124c2b930"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.203  Python-3.10.18 torch-2.8.0+cpu CPU (Intel Core i5-1035G1 1.00GHz)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\fayaf\\Downloads\\FaceRec_Rahmath\\Q2_Rahmath\\vehicle_dataset\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8_vehicle_model, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:\\Users\\fayaf\\Downloads\\FaceRec_Rahmath\\Q2_Rahmath, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\fayaf\\Downloads\\FaceRec_Rahmath\\Q2_Rahmath\\yolov8_vehicle_model, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=14\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3783802  ultralytics.nn.modules.head.Detect           [14, [192, 384, 576]]         \n",
            "Model summary: 169 layers, 25,864,426 parameters, 25,864,410 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.40.1 ms, read: 435.975.4 MB/s, size: 763.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\fayaf\\Downloads\\FaceRec_Rahmath\\Q2_Rahmath\\vehicle_dataset\\labels\\train.cache... 23 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 23/23  0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.30.3 ms, read: 494.491.2 MB/s, size: 822.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\fayaf\\Downloads\\FaceRec_Rahmath\\Q2_Rahmath\\vehicle_dataset\\labels\\val.cache... 12 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 12/12  0.0s\n",
            "Plotting labels to C:\\Users\\fayaf\\Downloads\\FaceRec_Rahmath\\Q2_Rahmath\\yolov8_vehicle_model\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mC:\\Users\\fayaf\\Downloads\\FaceRec_Rahmath\\Q2_Rahmath\\yolov8_vehicle_model\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# 1. Load pretrained YOLOv8 model\n",
        "model = YOLO(\"yolov8m.pt\")   \n",
        "\n",
        "# 2. Train on CPU\n",
        "results = model.train(\n",
        "    data=r\"C:\\Users\\fayaf\\Downloads\\FaceRec_Rahmath\\Q2_Rahmath\\vehicle_dataset\\data.yaml\",\n",
        "    epochs=60,\n",
        "    batch=8,                 \n",
        "    imgsz=640,\n",
        "    device=\"cuda\",            \n",
        "    workers=4,               \n",
        "    optimizer=\"AdamW\",\n",
        "    lr0=0.001,\n",
        "    weight_decay=0.0005,\n",
        "    augment=True,\n",
        "    mosaic=1.0,\n",
        "    mixup=0.2,\n",
        "    project=r\"C:\\Users\\fayaf\\Downloads\\FaceRec_Rahmath\\Q2_Rahmath\",\n",
        "    name=\"yolov8_vehicle_model\",\n",
        "    pretrained=True\n",
        ")\n",
        "\n",
        "# 3. Check training results\n",
        "print(\"Training finished. Results are saved in:\")\n",
        "print(results.save_dir)\n",
        "\n",
        "# 4. Evaluate the trained model on validation set\n",
        "metrics = model.val()\n",
        "print(metrics)\n",
        "\n",
        "# 5. Run inference on a test image (just to check quickly)\n",
        "test_img = r\"C:\\Users\\fayaf\\Downloads\\FaceRec_Rahmath\\Q2_Rahmath\\vehicle_dataset\\q2_Images\\20250917.113850.167.J001A1.FL.FR.W8273T.NaN.jpg\"\n",
        "predictions = model.predict(source=test_img, save=True, conf=0.25)\n",
        "\n",
        "# Annotated result will be saved inside 'runs/detect/predict' folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKdTBQz0yCO4",
        "outputId": "cddac95f-6aec-453e-fe48-a0cc2a5884e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model: /content/Vehicle_Training/yolov8_vehicle_model4/weights/best.pt\n",
            "Running inference...\n",
            "✅ Annotated image saved at: /content/inference_results/annotated_result.jpg\n",
            "✅ JSON summary saved at: /content/inference_results/scene_summary.json\n",
            "Scene Summary: {\n",
            "  \"file\": \"20250915.172302.451.J001A1.FL.RE.PATRIOT1513.NaN.jpg\",\n",
            "  \"timestamp\": \"2025-09-28T07:08:05.593388\",\n",
            "  \"incoming_traffic\": \"Yes\",\n",
            "  \"outgoing_traffic\": \"Yes\",\n",
            "  \"total_vehicles\": 2,\n",
            "  \"vehicles\": [\n",
            "    {\n",
            "      \"type_class\": \"car\",\n",
            "      \"detection_confidence\": 0.9976,\n",
            "      \"color\": \"Gray\",\n",
            "      \"make\": \"toyota\",\n",
            "      \"logo_bbox\": [\n",
            "        1108,\n",
            "        932,\n",
            "        1161,\n",
            "        967\n",
            "      ],\n",
            "      \"vehicle_bbox\": [\n",
            "        889,\n",
            "        477,\n",
            "        1471,\n",
            "        1165\n",
            "      ],\n",
            "      \"license_plate_present\": \"Yes\",\n",
            "      \"license_plate_bbox\": [\n",
            "        1082,\n",
            "        991,\n",
            "        1194,\n",
            "        1043\n",
            "      ],\n",
            "      \"license_plate_color\": \"Blue\",\n",
            "      \"lane\": \"Right\",\n",
            "      \"direction\": \"Outgoing\",\n",
            "      \"notes\": [\n",
            "        \"plate_conf=0.86\",\n",
            "        \"logo_conf=0.736\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"type_class\": \"car\",\n",
            "      \"detection_confidence\": 0.7878,\n",
            "      \"color\": \"Blue\",\n",
            "      \"make\": \"Unknown\",\n",
            "      \"logo_bbox\": null,\n",
            "      \"vehicle_bbox\": [\n",
            "        565,\n",
            "        63,\n",
            "        867,\n",
            "        159\n",
            "      ],\n",
            "      \"license_plate_present\": \"Yes\",\n",
            "      \"license_plate_bbox\": [\n",
            "        651,\n",
            "        90,\n",
            "        752,\n",
            "        117\n",
            "      ],\n",
            "      \"license_plate_color\": \"Green\",\n",
            "      \"lane\": \"Left\",\n",
            "      \"direction\": \"Incoming\",\n",
            "      \"notes\": [\n",
            "        \"plate_conf=0.639\"\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# improved_vehicle_inference.py\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from datetime import datetime\n",
        "\n",
        "# -------- CONFIG --------\n",
        "SAVE_DIR = r\"C:\\Users\\fayaf\\Downloads\\FaceRec_Rahmath\\Q2_Rahmath\"\n",
        "CONF_THR = 0.25    # detection confidence threshold\n",
        "IOU_ASSOC_THRESH = 0.25\n",
        "MAX_TEXT_FONT = 28\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# -------- Auto-find best.pt --------\n",
        "def get_latest_best_pt(base_dir=\"runs/detect\"):\n",
        "    \"\"\"Find the most recent YOLO run with best.pt inside.\"\"\"\n",
        "    if not os.path.exists(base_dir):\n",
        "        raise FileNotFoundError(f\"No YOLO runs found in {base_dir}\")\n",
        "\n",
        "    run_dirs = [os.path.join(base_dir, d) for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
        "    if not run_dirs:\n",
        "        raise FileNotFoundError(\"No training run directories found.\")\n",
        "\n",
        "    # pick the most recently modified run\n",
        "    latest_run = max(run_dirs, key=os.path.getmtime)\n",
        "    weights_path = os.path.join(latest_run, \"weights\", \"best.pt\")\n",
        "    if not os.path.exists(weights_path):\n",
        "        raise FileNotFoundError(f\"best.pt not found in {latest_run}\")\n",
        "    return weights_path\n",
        "\n",
        "try:\n",
        "    MODEL_PATH = get_latest_best_pt()\n",
        "except FileNotFoundError as e:\n",
        "    print(\"⚠️ Could not auto-locate best.pt. Please train a model first or set MODEL_PATH manually.\")\n",
        "    raise e\n",
        "\n",
        "# -------- Test image --------\n",
        "TEST_IMG = r\"C:\\Users\\fayaf\\Downloads\\FaceRec_Rahmath\\Q2_Rahmath\\vehicle_dataset\\q2_Images\\20250917.113850.167.J001A1.FL.FR.W8273T.NaN.jpg\"\n",
        "\n",
        "# -------- Helpers --------\n",
        "def iou(boxA, boxB):\n",
        "    # boxes as [x1,y1,x2,y2]\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "    interW = max(0, xB - xA)\n",
        "    interH = max(0, yB - yA)\n",
        "    interArea = interW * interH\n",
        "    boxAArea = max(0, boxA[2] - boxA[0]) * max(0, boxA[3] - boxA[1])\n",
        "    boxBArea = max(0, boxB[2] - boxB[0]) * max(0, boxB[3] - boxB[1])\n",
        "    denom = float(boxAArea + boxBArea - interArea + 1e-9)\n",
        "    return interArea / denom if denom > 0 else 0.0\n",
        "\n",
        "def box_center(box):\n",
        "    x1,y1,x2,y2 = box\n",
        "    return ((x1+x2)/2.0, (y1+y2)/2.0)\n",
        "\n",
        "def mean_hsv_color_name(bgr_crop):\n",
        "    \"\"\"Return robust color name using HSV mean and heuristics.\"\"\"\n",
        "    if bgr_crop is None or bgr_crop.size == 0:\n",
        "        return \"Unknown\"\n",
        "    hsv = cv2.cvtColor(bgr_crop, cv2.COLOR_BGR2HSV)\n",
        "    h_mean = float(np.mean(hsv[:,:,0]))  # 0..179\n",
        "    s_mean = float(np.mean(hsv[:,:,1]))  # 0..255\n",
        "    v_mean = float(np.mean(hsv[:,:,2]))  # 0..255\n",
        "\n",
        "    # brightness/sat based checks for white/black/gray\n",
        "    if v_mean > 220 and s_mean < 30:\n",
        "        return \"White\"\n",
        "    if v_mean < 40:\n",
        "        return \"Black\"\n",
        "    if s_mean < 40 and 40 < v_mean < 220:\n",
        "        return \"Gray\"\n",
        "\n",
        "    # convert hue to degrees 0..360\n",
        "    hue_deg = (h_mean / 179.0) * 360.0\n",
        "\n",
        "    if (hue_deg <= 15) or (hue_deg > 345):\n",
        "        return \"Red\"\n",
        "    if 15 < hue_deg <= 45:\n",
        "        return \"Orange\"\n",
        "    if 45 < hue_deg <= 75:\n",
        "        return \"Yellow\"\n",
        "    if 75 < hue_deg <= 150:\n",
        "        return \"Green\"\n",
        "    if 150 < hue_deg <= 210:\n",
        "        return \"Cyan\"\n",
        "    if 210 < hue_deg <= 270:\n",
        "        return \"Blue\"\n",
        "    if 270 < hue_deg <= 315:\n",
        "        return \"Purple\"\n",
        "    if 315 < hue_deg <= 345:\n",
        "        return \"Pink\"\n",
        "    return \"Unknown\"\n",
        "\n",
        "def safe_int_box(box):\n",
        "    return [int(max(0, round(x))) for x in box]\n",
        "\n",
        "def try_load_font(preferred_size=18):\n",
        "    # Try common TTFs (Colab/Ubuntu/Windows). Fall back to None.\n",
        "    candidates = [\n",
        "        \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\",  # linux\n",
        "        \"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\",\n",
        "        \"C:/Windows/Fonts/Arial.ttf\",  # windows\n",
        "        \"C:/Windows/Fonts/arial.ttf\"\n",
        "    ]\n",
        "    for path in candidates:\n",
        "        try:\n",
        "            font = ImageFont.truetype(path, preferred_size)\n",
        "            return font\n",
        "        except Exception:\n",
        "            continue\n",
        "    return None  # fallback to cv2.putText if None\n",
        "\n",
        "def draw_text_pil(img_bgr, text, xy, font=None, text_color=(255,255,255), bg_color=(0,0,0), padding=6):\n",
        "    \"\"\"Draw nicer text using PIL and return BGR image\"\"\"\n",
        "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "    pil = Image.fromarray(img_rgb)\n",
        "    draw = ImageDraw.Draw(pil)\n",
        "\n",
        "    if font is None:\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    # Use textbbox instead of textsize\n",
        "    bbox = draw.textbbox((0, 0), text, font=font)\n",
        "    text_w, text_h = bbox[2] - bbox[0], bbox[3] - bbox[1]\n",
        "\n",
        "    x, y = xy\n",
        "    rect = [x, y, x + text_w + padding, y + text_h + padding//2]\n",
        "    draw.rectangle(rect, fill=bg_color)\n",
        "    draw.text((x+padding//2, y), text, fill=text_color, font=font)\n",
        "\n",
        "    out = cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)\n",
        "    return out\n",
        "\n",
        "\n",
        "# -------- Load model & image --------\n",
        "print(\"Loading model:\", MODEL_PATH)\n",
        "model = YOLO(MODEL_PATH)\n",
        "\n",
        "img = cv2.imread(TEST_IMG)\n",
        "if img is None:\n",
        "    raise FileNotFoundError(\"Could not load TEST_IMG: \" + TEST_IMG)\n",
        "h, w, _ = img.shape\n",
        "orig_img = img.copy()\n",
        "\n",
        "# -------- Run inference --------\n",
        "print(\"Running inference...\")\n",
        "results = model.predict(source=TEST_IMG, conf=CONF_THR, verbose=False)  # list of Results\n",
        "# results may contain 1 element (image)\n",
        "if len(results) == 0:\n",
        "    detections = []\n",
        "else:\n",
        "    r = results[0]\n",
        "    boxes_xyxy = r.boxes.xyxy.cpu().numpy() if hasattr(r.boxes, 'xyxy') else np.array([])\n",
        "    confs = r.boxes.conf.cpu().numpy() if hasattr(r.boxes, 'conf') else np.array([])\n",
        "    classes = r.boxes.cls.cpu().numpy().astype(int) if hasattr(r.boxes, 'cls') else np.array([])\n",
        "    detections = []\n",
        "    for box, cls, conf in zip(boxes_xyxy, classes, confs):\n",
        "        detections.append({\n",
        "            \"box\": [float(box[0]), float(box[1]), float(box[2]), float(box[3])],\n",
        "            \"class\": int(cls),\n",
        "            \"conf\": float(conf)\n",
        "        })\n",
        "\n",
        "# -------- Categorize detections --------\n",
        "names = model.names  # class idx -> name\n",
        "vehicle_labels = set([\"car\", \"truck\", \"bus\", \"bike\", \"motorbike\", \"motorcycle\"])  # extend as your model uses\n",
        "plate_label_names = set([\"license_plate\", \"plate\", \"number_plate\"])\n",
        "# car brand labels (as predicted by model) - include whatever classes your model has for logos\n",
        "brand_labels = set([\n",
        "    'nissan', 'toyota', 'isuzu', 'mitsubishi', 'proton', 'mazda', 'mercedes', 'honda', 'ford','bmw','audi','chevrolet'])\n",
        "\n",
        "vehicles = []\n",
        "plates = []\n",
        "logos = []\n",
        "\n",
        "for det in detections:\n",
        "    box = det[\"box\"]\n",
        "    cls = det[\"class\"]\n",
        "    conf = det[\"conf\"]\n",
        "    label = names.get(cls, str(cls)).lower()\n",
        "    if label in vehicle_labels:\n",
        "        vehicles.append((label, box, conf, cls))\n",
        "    elif label in plate_label_names:\n",
        "        plates.append((label, box, conf, cls))\n",
        "    elif label in brand_labels:\n",
        "        logos.append((label, box, conf, cls))\n",
        "    else:\n",
        "        # try heuristic: if name contains 'plate' -> plate, contains brand substrings -> logo\n",
        "        if \"plate\" in label:\n",
        "            plates.append((label, box, conf, cls))\n",
        "        elif any(b in label for b in [\"nissan\",\"toyota\",\"honda\",\"logo\",\"mercedes\",\"ford\",\"bmw\",\"audi\",\"chev\",\"mazda\",\"isuzu\",\"proton\"]):\n",
        "            logos.append((label, box, conf, cls))\n",
        "        else:\n",
        "            # ignore or keep for debug\n",
        "            pass\n",
        "\n",
        "# -------- Associate plates/logos with vehicles --------\n",
        "scene_summary = {\n",
        "    \"file\": os.path.basename(TEST_IMG),\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"incoming_traffic\": False,\n",
        "    \"outgoing_traffic\": False,\n",
        "    \"total_vehicles\": 0,\n",
        "    \"vehicles\": []\n",
        "}\n",
        "\n",
        "font = try_load_font(preferred_size=18)  # try to load TTF for nicer rendering\n",
        "\n",
        "for vlabel, vboxf, vconf, vcls in vehicles:\n",
        "    vbox = safe_int_box(vboxf)\n",
        "    x1,y1,x2,y2 = vbox\n",
        "    if x2 <= x1 or y2 <= y1:\n",
        "        continue\n",
        "    cx, cy = int((x1+x2)/2), int((y1+y2)/2)\n",
        "    lane = \"Left\" if cx < w//2 else \"Right\"\n",
        "    direction = \"Incoming\" if cy < h//2 else \"Outgoing\"\n",
        "\n",
        "    # Vehicle crop and color\n",
        "    vehicle_crop = orig_img[y1:y2, x1:x2].copy()\n",
        "    color = mean_hsv_color_name(vehicle_crop)\n",
        "\n",
        "    vehicle_info = {\n",
        "        \"type_class\": vlabel,\n",
        "        \"detection_confidence\": round(vconf, 4),\n",
        "        \"color\": color,\n",
        "        \"make\": \"Unknown\",\n",
        "        \"logo_bbox\": None,\n",
        "        \"vehicle_bbox\": [x1, y1, x2, y2],\n",
        "        \"license_plate_present\": \"No\",\n",
        "        \"license_plate_bbox\": None,\n",
        "        \"license_plate_color\": None,\n",
        "        \"lane\": lane,\n",
        "        \"direction\": direction,\n",
        "        \"notes\": []\n",
        "    }\n",
        "\n",
        "    # Match license plate: prefer plate center inside vehicle OR IOU > threshold\n",
        "    matched_plate = None\n",
        "    for plabel, pboxf, pconf, pcls in plates:\n",
        "        pbox = safe_int_box(pboxf)\n",
        "        if iou(vbox, pbox) > IOU_ASSOC_THRESH:\n",
        "            matched_plate = (plabel, pbox, pconf)\n",
        "            break\n",
        "        # center-in-vehicle test\n",
        "        pcx,pcy = box_center(pbox)\n",
        "        if (pcx >= x1 and pcx <= x2 and pcy >= y1 and pcy <= y2):\n",
        "            matched_plate = (plabel, pbox, pconf)\n",
        "            break\n",
        "\n",
        "    if matched_plate:\n",
        "        plabel, pbox, pconf = matched_plate\n",
        "        px1,py1,px2,py2 = pbox\n",
        "        plate_crop = orig_img[py1:py2, px1:px2].copy()\n",
        "        plate_color = mean_hsv_color_name(plate_crop)\n",
        "        vehicle_info[\"license_plate_present\"] = \"Yes\"\n",
        "        vehicle_info[\"license_plate_bbox\"] = [px1,py1,px2,py2]\n",
        "        vehicle_info[\"license_plate_color\"] = plate_color\n",
        "        vehicle_info[\"notes\"].append(f\"plate_conf={round(pconf,3)}\")\n",
        "\n",
        "    # Match logo: prefer logo center inside vehicle OR IOU\n",
        "    matched_logo = None\n",
        "    for llabel, lboxf, lconf, lcls in logos:\n",
        "        lbox = safe_int_box(lboxf)\n",
        "        if iou(vbox, lbox) > IOU_ASSOC_THRESH:\n",
        "            matched_logo = (llabel, lbox, lconf)\n",
        "            break\n",
        "        lcx,lcy = box_center(lbox)\n",
        "        if (lcx >= x1 and lcx <= x2 and lcy >= y1 and lcy <= y2):\n",
        "            matched_logo = (llabel, lbox, lconf)\n",
        "            break\n",
        "\n",
        "    if matched_logo:\n",
        "        llabel, lbox, lconf = matched_logo\n",
        "        lx1,ly1,lx2,ly2 = lbox\n",
        "        vehicle_info[\"make\"] = (llabel if llabel != \"logo\" else \"Unknown\")\n",
        "        vehicle_info[\"logo_bbox\"] = [lx1,ly1,lx2,ly2]\n",
        "        vehicle_info[\"notes\"].append(f\"logo_conf={round(lconf,3)}\")\n",
        "\n",
        "    # append and draw\n",
        "    scene_summary[\"vehicles\"].append(vehicle_info)\n",
        "\n",
        "    # draw bbox: color by direction (green incoming, red outgoing)\n",
        "    draw_color = (0,200,0) if direction == \"Incoming\" else (0,0,200)\n",
        "    cv2.rectangle(img, (x1,y1), (x2,y2), draw_color, thickness=3)\n",
        "\n",
        "    # text for top-left: show type, color, make (short)\n",
        "    short_make = vehicle_info[\"make\"]\n",
        "    text = f\"{vlabel} | {color} | {short_make} | {lane} | {vconf:.2f}\"\n",
        "    # Use PIL draw for nicer font if available\n",
        "    if font is not None:\n",
        "        img = draw_text_pil(\n",
        "            img, text, (x1, max(0, y1-30)),\n",
        "            font=ImageFont.truetype(font.path, 18) if hasattr(font, \"path\") else font,\n",
        "            text_color=(255,255,255), bg_color=(0,0,0)\n",
        "    )       \n",
        "    else:\n",
        "        cv2.putText(img, text, (x1, max(15, y1-10)), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0,0,0), 4, cv2.LINE_AA)\n",
        "        cv2.putText(img, text, (x1, max(15, y1-10)), cv2.FONT_HERSHEY_DUPLEX, 0.7, (255,255,255), 1, cv2.LINE_AA)\n",
        "\n",
        "    # draw plate bbox\n",
        "    if vehicle_info[\"license_plate_present\"] == \"Yes\":\n",
        "        px1,py1,px2,py2 = vehicle_info[\"license_plate_bbox\"]\n",
        "        cv2.rectangle(img, (px1,py1), (px2,py2), (0,255,255), 2)\n",
        "        plate_text = f\"Plate: {vehicle_info['license_plate_present']}\"\n",
        "        if font is not None:\n",
        "            img = draw_text_pil(img, plate_text, (px1, py2 + 4), font=font,\n",
        "                            text_color=(0,0,0), bg_color=(255,255,0))\n",
        "        else:\n",
        "            cv2.putText(img, plate_text, (px1, py2 + 16), cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,0,0), 3)\n",
        "            cv2.putText(img, plate_text, (px1, py2 + 16), cv2.FONT_HERSHEY_DUPLEX, 0.5, (255,255,255), 1)\n",
        "\n",
        "\n",
        "    # draw logo bbox\n",
        "    if vehicle_info[\"logo_bbox\"]:\n",
        "        lx1,ly1,lx2,ly2 = vehicle_info[\"logo_bbox\"]\n",
        "        cv2.rectangle(img, (lx1,ly1), (lx2,ly2), (255,0,0), 2)\n",
        "        logo_text = f\"{vehicle_info['make']}\"\n",
        "        if font is not None:\n",
        "            img = draw_text_pil(img, logo_text, (lx1, max(0, ly1-24)), font=font, text_color=(255,255,255), bg_color=(0,0,255))\n",
        "        else:\n",
        "            cv2.putText(img, logo_text, (lx1, max(12, ly1-6)), cv2.FONT_HERSHEY_DUPLEX, 0.6, (0,0,0), thickness=3)\n",
        "            cv2.putText(img, logo_text, (lx1, max(12, ly1-6)), cv2.FONT_HERSHEY_DUPLEX, 0.6, (255,255,255), thickness=1)\n",
        "\n",
        "# -------- Scene level info --------\n",
        "scene_summary[\"total_vehicles\"] = len(scene_summary[\"vehicles\"])\n",
        "for v in scene_summary[\"vehicles\"]:\n",
        "    # deduce incoming/outgoing from per-vehicle direction\n",
        "    if v[\"direction\"] == \"Incoming\":\n",
        "        scene_summary[\"incoming_traffic\"] = True\n",
        "    if v[\"direction\"] == \"Outgoing\":\n",
        "        scene_summary[\"outgoing_traffic\"] = True\n",
        "\n",
        "scene_summary[\"incoming_traffic\"] = \"Yes\" if scene_summary[\"incoming_traffic\"] else \"No\"\n",
        "scene_summary[\"outgoing_traffic\"] = \"Yes\" if scene_summary[\"outgoing_traffic\"] else \"No\"\n",
        "\n",
        "# banner\n",
        "banner = f\"Vehicles: {scene_summary['total_vehicles']} | Incoming: {scene_summary['incoming_traffic']} | Outgoing: {scene_summary['outgoing_traffic']}\"\n",
        "# draw banner background rectangle\n",
        "cv2.rectangle(img, (0,0), (w, 36), (0,0,0), -1)\n",
        "cv2.putText(img, banner, (12, 24), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,255,255), 2, cv2.LINE_AA)\n",
        "\n",
        "# -------- Save outputs --------\n",
        "annotated_path = os.path.join(SAVE_DIR, \"annotated_result.jpg\")\n",
        "json_path = os.path.join(SAVE_DIR, \"scene_summary.json\")\n",
        "cv2.imwrite(annotated_path, img)\n",
        "with open(json_path, \"w\") as f:\n",
        "    json.dump(scene_summary, f, indent=4)\n",
        "\n",
        "print(f\"✅ Annotated image saved at: {annotated_path}\")\n",
        "print(f\"✅ JSON summary saved at: {json_path}\")\n",
        "print(\"Scene Summary:\", json.dumps(scene_summary, indent=2))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "FaceRec",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
